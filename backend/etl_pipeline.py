# etl_pipeline.py - å†å²æ•°æ®æ¸…æ´—å™¨
import csv
import os
import re
import json

# === é…ç½® ===
HISTORY_FOLDER = "historyData"  # å†å²æ•°æ®æº
OUTPUT_FILE = "output/price_history.csv"  # æ¸…æ´—åçš„å†å²å¤§è¡¨
PRODUCT_INFO_FILE = "output/products_db.json"  # å•†å“åŸºç¡€ä¿¡æ¯è¡¨


def extract_date_from_filename(filename):
    # ä» "20240418-1013..." æå– "2024-04-18"
    match = re.search(r"(\d{4})(\d{2})(\d{2})", filename)
    if match:
        return f"{match.group(1)}-{match.group(2)}-{match.group(3)}"
    return None


def clean_price(price_str):
    try:
        # å»æ‰ $ å’Œç©ºæ ¼ï¼Œæ¯”å¦‚ "$ 10.50" -> 10.5
        clean_str = re.sub(r'[^\d.]', '', str(price_str))
        return float(clean_str)
    except:
        return 0.0


def run_etl():
    print("ğŸ§¹ [ETL] å¯åŠ¨ï¼šæ­£åœ¨æ¸…æ´— data/history ä¸‹çš„å†å²æ•°æ®...")

    if not os.path.exists("output"): os.makedirs("output")
    if not os.path.exists(HISTORY_FOLDER):
        print(f"âŒ é”™è¯¯ï¼šæ‰¾ä¸åˆ° {HISTORY_FOLDER} æ–‡ä»¶å¤¹ï¼")
        return

    all_history = []
    unique_products = {}

    files = [f for f in os.listdir(HISTORY_FOLDER) if f.endswith(".csv")]
    print(f"ğŸ“‚ å‘ç° {len(files)} ä¸ªå†å²æ–‡ä»¶ã€‚")

    for filename in files:
        date_str = extract_date_from_filename(filename)
        if not date_str: continue

        path = os.path.join(HISTORY_FOLDER, filename)
        try:
            with open(path, 'r', encoding='utf-8-sig') as f:
                reader = csv.DictReader(f)
                for row in reader:
                    sku = row.get("è²¨å“ç·¨è™Ÿ")
                    price_raw = row.get("åƒ¹æ ¼")

                    if not sku: continue
                    price = clean_price(price_raw)
                    if price <= 0: continue

                    # å­˜å…¥å†å²è®°å½•
                    all_history.append({
                        "sku_id": sku,
                        "date": date_str,
                        "price": price,
                        "store": row.get("è¶…å¸‚ä»£è™Ÿ", "Unknown")
                    })

                    # æå–å•†å“ä¿¡æ¯ (ç”¨äºå‰ç«¯å±•ç¤º)
                    if sku not in unique_products:
                        unique_products[sku] = {
                            "sku_id": sku,
                            "name": row.get("è²¨å“åç¨±", "Unknown Name"),
                            "brand": row.get("å“ç‰Œ", "Unknown Brand"),
                            "cat": row.get("è²¨å“åˆ†é¡1", "General")
                        }
        except Exception as e:
            print(f"âš ï¸ æ— æ³•è¯»å– {filename}: {e}")

    # ä¿å­˜å†å²ä»·æ ¼å¤§è¡¨
    with open(OUTPUT_FILE, 'w', newline='', encoding='utf-8') as f:
        writer = csv.DictWriter(f, fieldnames=["sku_id", "date", "price", "store"])
        writer.writeheader()
        writer.writerows(all_history)

    # ä¿å­˜å•†å“åº“ (main.py éœ€è¦ç”¨åˆ°)
    with open(PRODUCT_INFO_FILE, 'w', encoding='utf-8') as f:
        json.dump(list(unique_products.values()), f, ensure_ascii=False, indent=2)

    print(f"âœ… [ETL] å®Œæˆï¼æå–äº† {len(all_history)} æ¡å†å²è®°å½•ã€‚")


if __name__ == "__main__":
    run_etl()